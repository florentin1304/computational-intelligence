{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch \n",
    "\n",
    "from utils.reproduce_functions import *\n",
    "from utils.mutation_functions import *\n",
    "from utils.parent_selection_functions import *\n",
    "from utils.other_fucntions import * \n",
    "from utils.network import *\n",
    "\n",
    "\n",
    "import lab9_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEM_SIZE = 10\n",
    "\n",
    "MU = 10\n",
    "LAMBDA = 20\n",
    "strategy = 'plus' # comma or plus\n",
    "\n",
    "MUTATION_PROB = 0.2\n",
    "DYNAMIC_MUTATION_PROB = True\n",
    "DIVERSITY_THRESHOLD = 20\n",
    "\n",
    "LENGTH_SOLUTION = 1000\n",
    "NUMBER_GENERATIONS = 2_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutate = one_bit_flip\n",
    "reproduce = uniform_crossover\n",
    "parent_selection = roulette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dataset = 100_000\n",
    "batch_size = 32\n",
    "name = \"a_lr_0.001_bs_32\"\n",
    "\n",
    "fitness = lab9_lib.make_problem(PROBLEM_SIZE)\n",
    "\n",
    "dataset = generate_dataset(fitness, length_solution=LENGTH_SOLUTION, size=n_dataset)\n",
    "train_dataloader, val_dataloader, test_dataloader = get_loaders(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[list(dataset.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "net = FitnessNet_b().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "train(model=net, \n",
    "      criterion=criterion, \n",
    "      optimizer=optimizer, \n",
    "      train_dataloader=train_dataloader, \n",
    "      val_dataloader=val_dataloader, \n",
    "      test_dataloader=test_dataloader,\n",
    "      device=device, \n",
    "      epochs=5)\n",
    "\n",
    "save = True\n",
    "if save:\n",
    "    save_model(net, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, high, low = plot_results(model=net, test_dataloader=test_dataloader, device=device, name=name, save=save, criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to test on a random element\n",
    "net.eval()\n",
    "\n",
    "value = torch.from_numpy(np.random.randint(2, size=LENGTH_SOLUTION)).float().unsqueeze(0).unsqueeze(1).to(device)\n",
    "print(net(value), value[0][0][:10], fitness(value[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_high_low(high=high, low=low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "def ga(fitness, parents, parents_evals, memoization=False, use_nn=False):\n",
    "    generation_convergence = -1\n",
    "    activate_nn = False\n",
    "    nn_threshold = 10_000\n",
    "\n",
    "    if use_nn:\n",
    "        pop_nn_history = {}\n",
    "        device = torch.device('cuda')\n",
    "        net = FitnessNet_b().to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "    \n",
    "    if memoization:\n",
    "        pop_history = {}\n",
    "        for i in range(len(parents)):\n",
    "            pop_history[parents[i].tobytes()] = (parents[i], parents_evals[i]) # CHANGED\n",
    "\n",
    "    for generation in tqdm(range(NUMBER_GENERATIONS)):\n",
    "        offsprings = []\n",
    "        offsprings_evals = []\n",
    "        while len(offsprings) < LAMBDA:\n",
    "            # Parent Selection\n",
    "            p1, p2 = parent_selection(parents, parents_evals) \n",
    "\n",
    "            # Reproduce Parents\n",
    "            off_spring = reproduce(p1, p2)\n",
    "\n",
    "            # Mutate Offspring\n",
    "            if DYNAMIC_MUTATION_PROB:\n",
    "                p_div = get_parents_diversity(p1, p2)\n",
    "                new_ind1 = mutate(off_spring, \\\n",
    "                                  mutation_probability=(1 - (min(p_div,LENGTH_SOLUTION/2)/(LENGTH_SOLUTION/2))) )\n",
    "            else:    \n",
    "                new_ind1 = mutate(off_spring, mutation_probability=MUTATION_PROB)\n",
    "            \n",
    "            # CHANGED\n",
    "            # Evaluate Offspring\n",
    "            if memoization:\n",
    "                new_ind1_eval = pop_history.get(new_ind1.tobytes())\n",
    "                if new_ind1_eval == None:\n",
    "                    if activate_nn:\n",
    "                        new_ind1_eval = net(torch.from_numpy(new_ind1).float().unsqueeze(0).unsqueeze(1).to(device))\n",
    "                        new_ind1_eval = new_ind1_eval.cpu().detach().numpy()[0][0]\n",
    "                        pop_nn_history[new_ind1.tobytes()] = (new_ind1, new_ind1_eval)\n",
    "                    else:\n",
    "                        new_ind1_eval = fitness(new_ind1)\n",
    "                        pop_history[new_ind1.tobytes()] = (new_ind1, new_ind1_eval)\n",
    "                else: \n",
    "                    new_ind1_eval = new_ind1_eval[1]\n",
    "            else:\n",
    "                new_ind1_eval = fitness(new_ind1)\n",
    "            # END CHANGED\n",
    "\n",
    "            # Add it to new population\n",
    "            offsprings.append(new_ind1)\n",
    "            offsprings_evals.append(new_ind1_eval)\n",
    "\n",
    "        # Create new population (with parents if plus, without if comma)\n",
    "        all_people = (parents if strategy=='plus' else []) + offsprings\n",
    "        all_evals = (parents_evals if strategy=='plus' else []) + offsprings_evals\n",
    "        best_people = np.argsort(all_evals)[::-1]\n",
    "\n",
    "        parents = []\n",
    "        parents_evals = []\n",
    "        for i in range(MU):\n",
    "            parents.append(all_people[best_people[i]])\n",
    "            parents_evals.append(all_evals[best_people[i]])\n",
    "            \n",
    "        if np.max(parents_evals) - 1.0 >= 0 and generation_convergence == -1:\n",
    "            generation_convergence = generation, fitness.calls\n",
    "        \n",
    "        # CHANGED\n",
    "        # at the end of each generation, if the number of known solutions is greater than the nn_threshold, activate the neural network\n",
    "        if use_nn and len(pop_history) > nn_threshold and not activate_nn:\n",
    "            activate_nn = True\n",
    "            train_dataloader, val_dataloader, test_dataloader = get_loaders(pop_history, batch_size=32, train_size=1.0, val_size=0.0, test_size=0.0)\n",
    "            print(\"Activating neural network\")\n",
    "            train(model=net, \n",
    "                  criterion=criterion, \n",
    "                  optimizer=optimizer, \n",
    "                  train_dataloader=train_dataloader, \n",
    "                  val_dataloader=val_dataloader, \n",
    "                  test_dataloader=test_dataloader,\n",
    "                  device=device, \n",
    "                  epochs=20)\n",
    "        \n",
    "\n",
    "    # take the 10 best solutions in pop_nn_history and evaluate them with the fitness function \n",
    "    if use_nn:\n",
    "        val = {}\n",
    "        best_nn_solutions = np.argsort([pop_nn_history[key][1] for key in pop_nn_history])[::-1][:10]\n",
    "        for i in best_nn_solutions:\n",
    "            key = list(pop_nn_history.keys())[i]\n",
    "            value = pop_nn_history[key]\n",
    "            val[key] = (value[0], fitness(value[0]))\n",
    "            print(f\"Value: {val[key][1]}\")\n",
    "            # END CHANGED\n",
    "        \n",
    "\n",
    "\n",
    "    return parents, parents_evals, generation_convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [00:59<00:00, 42.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.174\n",
      "Num fitness calls:  17296\n",
      "Generation, NumCalls @ fitness=1.0 :  -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fitness = lab9_lib.make_problem(PROBLEM_SIZE)\n",
    "parents = [generate_random_individual(length=LENGTH_SOLUTION) for _ in range(50)]\n",
    "parents_evals = [fitness(x) for x in parents]\n",
    "parents, parents_evals, gc = ga(fitness, parents, parents_evals, memoization=True, use_nn=False)\n",
    "i_best = np.argmax(parents_evals)\n",
    "# print(parents[i_best])\n",
    "print(\"Best score: \", parents_evals[i_best])\n",
    "print(\"Num fitness calls: \", fitness.calls)\n",
    "print(\"Generation, NumCalls @ fitness=1.0 : \", gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 497/2500 [00:12<00:49, 40.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activating neural network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\ProgramData\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  Loss:  0.0015974001726135612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1  Loss:  0.0006115005235187709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2  Loss:  7.604585698572919e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3  Loss:  1.6766853150329553e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4  Loss:  0.0028863665647804737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5  Loss:  0.002043954562395811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6  Loss:  0.0007391259423457086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7  Loss:  0.00021039802231825888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8  Loss:  0.0008222896722145379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9  Loss:  0.006657079327851534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10  Loss:  0.0002666704822331667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11  Loss:  0.0062418305315077305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12  Loss:  0.0019344359170645475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 497/2500 [00:23<00:49, 40.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  13  Loss:  0.003984506707638502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  14  Loss:  0.00017670696252025664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  15  Loss:  0.0008788231061771512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  16  Loss:  0.0004023535002488643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  17  Loss:  0.00019615520432125777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  18  Loss:  0.0009313744376413524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:15<00:00,  1.29it/s]\n",
      " 20%|██        | 504/2500 [00:28<27:27,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  19  Loss:  0.0003991955891251564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [01:45<00:00, 23.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value: 0.10645555557\n",
      "Value: 0.16745555569999998\n",
      "Value: 0.16735556669999999\n",
      "Value: 0.16744555560000002\n",
      "Value: 0.050835555557\n",
      "Value: 0.10645555557\n",
      "Value: 0.16745555569999998\n",
      "Value: 0.16745555569999998\n",
      "Value: 0.1674455557\n",
      "Value: 0.16744555560000002\n",
      "Best score:  0.1675555556\n",
      "Num fitness calls:  10027\n",
      "Generation, NumCalls @ fitness=1.0 :  -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fitness = lab9_lib.make_problem(PROBLEM_SIZE)\n",
    "parents = [generate_random_individual(length=LENGTH_SOLUTION) for _ in range(50)]\n",
    "parents_evals = [fitness(x) for x in parents]\n",
    "parents, parents_evals, gc = ga(fitness, parents, parents_evals, memoization=True, use_nn=True)\n",
    "i_best = np.argmax(parents_evals)\n",
    "# print(parents[i_best])\n",
    "print(\"Best score: \", parents_evals[i_best])\n",
    "print(\"Num fitness calls: \", fitness.calls)\n",
    "print(\"Generation, NumCalls @ fitness=1.0 : \", gc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
