# Computational Intelligence 2023/2024

Repository for the Computational Intelligence course taught by [Giovanni Squillero](https://github.com/squillero) during the A.A. 2023/2024. 
Regarding the Labs Hope you enjoy the contents as much as we did while creating them! ðŸ¤—

---

## Course Activity Log

| **Activity**               | **Description**                                                                                                                                                                                               | **Link**                                                                                                     |
|---------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------|
| Lab 1                     | Implementation of the A* search algorithm for the set covering problem by proposing new heuristic and cost functions                                                                                        | [Link to Lab 1](https://github.com/florentin1304/computational-intelligence/tree/main/Laboratories/Lab1)       |
| Halloween challenge        | Took part in the Halloween Challenge. New steady-state algorithm for the set covering problem proposed based on binary search and taboo search for exhaustive local optimum search                                | [Link to Halloween Challenge](https://github.com/florentin1304/computational-intelligence/blob/main/Other%20activities/halloween_challange_setcovering_singlestate.ipynb) |
| Lab 2 on time delivery      | Implementation of a Nim agent optimized through an Evolutionary Strategy. Three solutions proposed: a weighted rule optimization agent, a state predicting agent through evolutionary-strategy-optimized logistic regressor, and a state predicting agent through evolutionary-strategy-optimized neural network. The best results came from the state predicting NIM agent through an evolutionary-strategy-optimized logistic classifier. | [Link to Lab 2](https://github.com/florentin1304/computational-intelligence/tree/main/Laboratories/Lab2)       |
| Lab 2 post deadline edits  | More experiments and in-depth analysis done after the deadline with the intent of gathering more data for the class presentation and implementing some of the reviewers' ideas                                   | [Link to Lab 2 (after deadline)](https://github.com/florentin1304/computational-intelligence/tree/main/Laboratories/Lab2_after_deadline) |
| Lab 2 class presentation    | During the lecture of 23/11/2023, I presented the logistic-regressor Nim agent, explaining the theory behind the solution and the methods of its implementation                                           | [Link to presentation](https://github.com/florentin1304/computational-intelligence/tree/main/Laboratories/Lab2_after_deadline) |
| Lab 2 reviews               | Reviewed two of my peers' Nim-agent solutions.                                                                                                                                                               | [Luca&nbsp;Catalano](https://github.com/LucaCatalano13/Computational-Intelligence/issues/1) and [Simone&nbsp;Borella](https://github.com/SimoneBorella/computational-intelligence/issues/3) |
| Lab 2 pull request          | Created a pull request to add the logistic regressor Nim agent as a contribution to the course                                                                                                             | -                                                                                                            |
| Lab 9 on time delivery      | In-depth benchmark of genetic algorithms variations applied to the one-max problem. Benchmark for multi-population strategies (islands) and variations (Valhalla Island, Segregation Islands). Proposal of Expert Islands variation where each population is responsible for a sub-part of the solution, achieving top results for the proposed problem. Collaboration with Luca Catalano (s308658) and Claudio Savelli (s317680) | [Link to Lab 9](https://github.com/florentin1304/computational-intelligence/tree/main/Laboratories/Lab9)       |
| Lab 9 post deadline edits   | More experiments and in-depth analysis done after the deadline with the intent of gathering more data for the class presentation and implementing some of the reviewers' ideas                                  | [Link to Lab 9 (after deadline)](https://github.com/florentin1304/computational-intelligence/tree/main/Laboratories/Lab9_after_deadline) |
| Lab 9 class presentation    | During the lecture of 11/12/2023, I presented the work done for Lab9 (along with my two other colleagues)                                                                                                | [Link to the presentation](https://github.com/florentin1304/computational-intelligence/tree/main/Laboratories/Lab9_after_deadline) |
| Lab 9 reviews               | Reviewed two of my peers' one-max problem solutions.                                                                                                                                                        | [Riccardo&nbsp;Cardona](https://github.com/Riden15/Computational-Intelligence/issues/5) and [Simone&nbsp;Borella](https://github.com/SimoneBorella/computational-intelligence/issues/6) |
| Lab 10 on time delivery     | The objective of this laboratory was to create a TicTacToe player agent using some reinforcement learning algorithm. The Q-Learning algorithm was used. Training was done against a random player (ensuring exploration from the opponent's side) and an informed player who always played the optimal move based on the magic-square heuristic | [Link to Lab 10](https://github.com/florentin1304/computational-intelligence/tree/main/Laboratories/Lab10)     |
| Lab 10 reviews              | Reviewed two of my peers' TicTacToe RL-agent solutions.                                                                                                                                                     | [Enrico&nbsp;Capuano](https://github.com/enricocapuano/computationalintelligence/issues/5) and [Simone&nbsp;Giambrone](https://github.com/JustLooller/Computational-Intelligence/issues/3) |
| Exam Project (Quixo Game Agent) | Implemented multiple solutions for the Quixo Game agents and a GUI for the game. The first agent implemented was a MinMax search (with Alpha-Beta pruning) algorithm agent, improved by adding a local breadth-first search and ordering the various moves to pick the most locally-promising move, thus speeding up the search by allowing the less promising moves to be pruned straight-away. The second agent was an implementation of AlphaZero for the Quixo Game, using a mixture of Monte Carlo Tree Search and Deep Learning methods. Finally, a GUI was developed to inspect the various agents playing against each other (and also testing them by playing myself against them). The final project was done in collaboration with Luca Catalano (s308658) and Claudio Savelli (s317680) | [Link to Exam Project](https://github.com/florentin1304/computational-intelligence/tree/main/Exam%20Quixo) |
| Extra: SCD presentation    | Presentation of the student team SCD (Squadra Corse Driverless) along with one of my peers Simone Borella (s317774)                                                                                        | -                                                                                                            |



### Disclaimer

Even though most of the code presented in this repo has been produced by the authors, or sometimes by the Professor during lectures, some pieces have been eventually developed through the help provided by several discussions on [Stack Overflow](https://stackoverflow.com/) and by AI tools like [ChatGPT](https://chat.openai.com/) (version 3.5). These have represented a great starting point for creating our own custom solutions!
